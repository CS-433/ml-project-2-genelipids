{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for computation\n",
      "Number of CPU cores available: 16\n",
      "Number of threads set for PyTorch: 16\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import cKDTree\n",
    "from pycaret.regression import *\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Check for GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "use_gpu = torch.cuda.is_available()\n",
    "num_cores = os.cpu_count()\n",
    "torch.set_num_threads(num_cores)\n",
    "print(f'Using {device} for computation')\n",
    "\n",
    "if not use_gpu:\n",
    "    print(f\"Number of CPU cores available: {num_cores}\")\n",
    "    print(f\"Number of threads set for PyTorch: {torch.get_num_threads()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipid_path = 'data/section12/lipids_section_12.parquet'\n",
    "gene_path = 'data/section12/genes_section_12.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_weight(dists, std):\n",
    "    return torch.exp(-0.5 * (dists / std) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(dists, avg_dist, factor):\n",
    "    return torch.exp(-factor * (dists - avg_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logarithmic_weight(dists):\n",
    "    adjusted_dists = dists + 1e-6\n",
    "    return -torch.log(adjusted_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_distance(dists):\n",
    "    dists = torch.clamp(dists, min=1e-6)\n",
    "    return 1.0 / dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "lipids_section_12 = pd.read_parquet(lipid_path, engine='pyarrow')\n",
    "genes_section_12 = pd.read_parquet(gene_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cKDTree for fast query of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KDTree object for the genes\n",
    "genes_coords = genes_section_12[['y_ccf', 'z_ccf']].values\n",
    "genes_kdtree = cKDTree(genes_coords)\n",
    "\n",
    "# Extract coordinates for lipids\n",
    "lipids_coords = lipids_section_12[['y_ccf', 'z_ccf']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of the closest gene for each lipid point\n",
    "_, indices = genes_kdtree.query(lipids_coords, k=1)\n",
    "\n",
    "# Initialize an empty array for aggregated gene data\n",
    "aggregated_gene_data = np.zeros((len(lipids_coords), genes_section_12.iloc[:, 46:-50].shape[1]))\n",
    "\n",
    "# Aggregate gene data based on the closest neighbor\n",
    "for i, gene_index in enumerate(indices):\n",
    "    aggregated_gene_data[i] = genes_section_12.iloc[gene_index, 46:-50]\n",
    "\n",
    "# Convert the aggregated data into a DataFrame\n",
    "aggregated_gene_data_df = pd.DataFrame(aggregated_gene_data, columns=genes_section_12.columns[46:-50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average of nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b26815fbbc407f93eaccc4ae0977d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating Data:   0%|          | 0/89395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query to get the 5000 closest genes for each lipid point\n",
    "_, indices = genes_kdtree.query(lipids_coords, k=1000)\n",
    "\n",
    "# Convert indices and gene data to PyTorch tensors\n",
    "indices_tensor = torch.tensor(indices, dtype=torch.long).to(device)\n",
    "gene_data_tensor = torch.tensor(genes_section_12.iloc[:, 46:-50].values).to(device)\n",
    "n_genes = gene_data_tensor.shape[1]\n",
    "\n",
    "def aggregate_data(i, indices, gene_data, n_genes):\n",
    "    gene_indices = indices[i]\n",
    "    data = gene_data[gene_indices]\n",
    "    return data.mean(axis=0) if len(gene_indices) > 0 else torch.zeros(n_genes, device=device)\n",
    "\n",
    "# Initialize a tensor for aggregated gene data\n",
    "aggregated_gene_data = torch.zeros((len(lipids_coords), n_genes), device=device)\n",
    "\n",
    "# Perform the aggregation\n",
    "for i in tqdm(range(len(lipids_coords)), desc='Aggregating Data'):\n",
    "    aggregated_gene_data[i] = aggregate_data(i, indices_tensor, gene_data_tensor, n_genes)\n",
    "    \n",
    "# Move the results to CPU and convert to NumPy\n",
    "aggregated_gene_data_cpu = aggregated_gene_data.to('cpu').numpy()\n",
    "\n",
    "# Convert to DataFrame\n",
    "aggregated_gene_data_df = pd.DataFrame(aggregated_gene_data_cpu, columns=genes_section_12.columns[46:-50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Distance Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da88d4be75a45cb8e37b75d82aacc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating Data:   0%|          | 0/89395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the distances and indices of the 1000 closest genes for each lipid point\n",
    "distances, indices = genes_kdtree.query(lipids_coords, k=1000)\n",
    "\n",
    "# Convert distances and indices to PyTorch tensors\n",
    "distances_tensor = torch.tensor(distances, device=device)\n",
    "indices_tensor = torch.tensor(indices, dtype=torch.long, device=device)\n",
    "\n",
    "# Convert gene data to tensor\n",
    "gene_data_tensor = torch.tensor(genes_section_12.iloc[:, 46:-50].values, device=device)\n",
    "n_genes = gene_data_tensor.shape[1]\n",
    "\n",
    "def aggregate_data(i, distances, indices, gene_data):\n",
    "    dists = distances[i]\n",
    "    gene_indices = indices[i]\n",
    "    weights = inverse_distance(dists)\n",
    "    normalized_weights = weights / weights.sum()\n",
    "    weighted_data = gene_data[gene_indices] * normalized_weights[:, None]\n",
    "    return weighted_data.sum(axis=0)\n",
    "\n",
    "aggregated_gene_data = torch.zeros((len(lipids_coords), n_genes), device=device)\n",
    "\n",
    "for i in tqdm(range(len(lipids_coords)), desc='Aggregating Data'):\n",
    "    aggregated_gene_data[i] = aggregate_data(i, distances_tensor, indices_tensor, gene_data_tensor)\n",
    "\n",
    "aggregated_gene_data_cpu = aggregated_gene_data.to('cpu').numpy()\n",
    "aggregated_gene_data_df = pd.DataFrame(aggregated_gene_data_cpu, columns=genes_section_12.columns[46:-50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logarithm Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b40d874e294c52ad1a5404c80021b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating data:   0%|          | 0/89395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m weighted_sum\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Run the aggregation function\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m aggregated_gene_data \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Move the results back to CPU and convert to a DataFrame\u001b[39;00m\n\u001b[1;32m     24\u001b[0m aggregated_gene_data_cpu \u001b[38;5;241m=\u001b[39m aggregated_gene_data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m, in \u001b[0;36maggregate_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     normalized_weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m/\u001b[39m weights\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     16\u001b[0m     weighted_data \u001b[38;5;241m=\u001b[39m genes_data[gene_indices] \u001b[38;5;241m*\u001b[39m normalized_weights[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m---> 17\u001b[0m     weighted_sum[i] \u001b[38;5;241m=\u001b[39m \u001b[43mweighted_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weighted_sum\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "distances, indices = genes_kdtree.query(lipids_coords, k=5000)\n",
    "\n",
    "# Convert data to PyTorch tensors and move to the selected device\n",
    "distances = torch.tensor(distances).to(device)\n",
    "indices = torch.tensor(indices, dtype=torch.long).to(device)  # Indices should be of type long\n",
    "genes_data = torch.tensor(genes_section_12.iloc[:, 46:-50].values).to(device)\n",
    "\n",
    "# Function to aggregate data using the new weighting scheme with PyTorch\n",
    "def aggregate_data():\n",
    "    weighted_sum = torch.zeros((len(lipids_coords), genes_section_12.iloc[:, 46:-50].shape[1]), device=device)\n",
    "    for i in tqdm(range(len(lipids_coords)), desc='Aggregating data'):\n",
    "        dists = distances[i]\n",
    "        gene_indices = indices[i]\n",
    "        weights = logarithmic_weight(dists)\n",
    "        normalized_weights = weights / weights.sum()\n",
    "        weighted_data = genes_data[gene_indices] * normalized_weights[:, None]\n",
    "        weighted_sum[i] = weighted_data.sum(axis=0)\n",
    "    return weighted_sum\n",
    "\n",
    "# Run the aggregation function\n",
    "aggregated_gene_data = aggregate_data()\n",
    "\n",
    "# Move the results back to CPU and convert to a DataFrame\n",
    "aggregated_gene_data_cpu = aggregated_gene_data.to('cpu').numpy()\n",
    "aggregated_gene_data_df = pd.DataFrame(aggregated_gene_data_cpu, columns=genes_section_12.columns[46:-50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc508a7d1b648e9a44d0052c9fe1ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating Data:   0%|          | 0/89395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert distances and indices to tensors\n",
    "distances, indices = genes_kdtree.query(lipids_coords, k=1000)\n",
    "distances_tensor = torch.tensor(distances, device=device)\n",
    "indices_tensor = torch.tensor(indices, dtype=torch.long, device=device)\n",
    "\n",
    "# Calculate average distance and convert to tensor\n",
    "average_closest_distance_tensor = torch.mean(distances_tensor)\n",
    "\n",
    "# Convert gene data to tensor\n",
    "gene_data_tensor = torch.tensor(genes_section_12.iloc[:, 46:-50].values, device=device)\n",
    "n_genes = gene_data_tensor.shape[1]\n",
    "\n",
    "def aggregate_data(i, distances, indices, avg_dist, gene_data):\n",
    "    dists = distances[i]\n",
    "    gene_indices = indices[i]\n",
    "    weights = exponential_decay(dists, avg_dist, 0.1)\n",
    "    weighted_data = gene_data[gene_indices] * weights[:, None]\n",
    "    return weighted_data.sum(axis=0) / weights.sum() if weights.sum() > 0 else torch.zeros(n_genes, device=device)\n",
    "\n",
    "aggregated_gene_data = torch.zeros((len(lipids_coords), n_genes), device=device)\n",
    "\n",
    "for i in tqdm(range(len(lipids_coords)), desc='Aggregating Data'):\n",
    "    aggregated_gene_data[i] = aggregate_data(i, distances_tensor, indices_tensor, average_closest_distance_tensor, gene_data_tensor)\n",
    "    \n",
    "aggregated_gene_data_cpu = aggregated_gene_data.to('cpu').numpy()\n",
    "aggregated_gene_data_df = pd.DataFrame(aggregated_gene_data_cpu, columns=genes_section_12.columns[46:-50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# K neighbors gaussian mean of genes for a given lipids datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c50361b9f8c487cbaf0952297249f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating Data:   0%|          | 0/89395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert distances and indices to tensors\n",
    "distances, indices = genes_kdtree.query(lipids_coords, k=1000)\n",
    "distances_tensor = torch.tensor(distances, device=device)\n",
    "indices_tensor = torch.tensor(indices, dtype=torch.long, device=device)\n",
    "\n",
    "# Calculate standard deviation of the distances\n",
    "std_closest_distance_tensor = torch.std(distances_tensor, dim=1)\n",
    "\n",
    "# Convert gene data to tensor\n",
    "gene_data_tensor = torch.tensor(genes_section_12.iloc[:, 46:-50].values, device=device)\n",
    "n_genes = gene_data_tensor.shape[1]\n",
    "\n",
    "def aggregate_data(i, distances, indices, std_dist, gene_data):\n",
    "    dists = distances[i]\n",
    "    gene_indices = indices[i]\n",
    "    weights = gaussian_weight(dists, std_dist[i])\n",
    "    weighted_data = gene_data[gene_indices] * weights[:, None]\n",
    "    return weighted_data.sum(axis=0) / weights.sum() if weights.sum() > 0 else torch.zeros(n_genes, device=device)\n",
    "\n",
    "aggregated_gene_data = torch.zeros((len(lipids_coords), n_genes), device=device)\n",
    "for i in tqdm(range(len(lipids_coords)), desc='Aggregating Data'):\n",
    "    aggregated_gene_data[i] = aggregate_data(i, distances_tensor, indices_tensor, std_closest_distance_tensor, gene_data_tensor)\n",
    "    \n",
    "# Move results to CPU\n",
    "aggregated_gene_data_cpu = aggregated_gene_data.to('cpu').numpy()\n",
    "\n",
    "# Convert to DataFrame\n",
    "aggregated_gene_data_df = pd.DataFrame(aggregated_gene_data_cpu, columns=genes_section_12.columns[46:-50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resulting genes and lipids DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_gene_data_df = np.log1p(aggregated_gene_data_df)\n",
    "section_12_lipids_only = lipids_section_12.iloc[:, 13:]\n",
    "\n",
    "aggregated_gene_data_df = aggregated_gene_data_df.reset_index(drop=True)\n",
    "section_12_lipids_only = section_12_lipids_only.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features and target dataframes\n",
    "features_df = aggregated_gene_data_df.copy()\n",
    "target_df = section_12_lipids_only.copy()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, target_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Export the full training and test sets to .h5 files\n",
    "X_train.to_parquet('data/train_features.parquet', engine='pyarrow')\n",
    "X_test.to_parquet('data/test_features.parquet', engine='pyarrow')\n",
    "y_train.to_parquet('data/train_targets.parquet', engine='pyarrow')\n",
    "y_test.to_parquet('data/test_targets.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try on a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f7a2b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f7a2b_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_f7a2b_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f7a2b_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_f7a2b_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f7a2b_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_f7a2b_row1_col1\" class=\"data row1 col1\" >PG(40:3) </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f7a2b_row2_col0\" class=\"data row2 col0\" >Original Data</td>\n",
       "      <td id=\"T_f7a2b_row2_col1\" class=\"data row2 col1\" >(62576, 501)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f7a2b_row3_col0\" class=\"data row3 col0\" >Missing Values</td>\n",
       "      <td id=\"T_f7a2b_row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f7a2b_row4_col0\" class=\"data row4 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_f7a2b_row4_col1\" class=\"data row4 col1\" >500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f7a2b_row5_col0\" class=\"data row5 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_f7a2b_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f7a2b_row6_col0\" class=\"data row6 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_f7a2b_row6_col1\" class=\"data row6 col1\" >(62576, 500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f7a2b_row7_col0\" class=\"data row7 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_f7a2b_row7_col1\" class=\"data row7 col1\" >(26819, 500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f7a2b_row8_col0\" class=\"data row8 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_f7a2b_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f7a2b_row9_col0\" class=\"data row9 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_f7a2b_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f7a2b_row10_col0\" class=\"data row10 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_f7a2b_row10_col1\" class=\"data row10 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f7a2b_row11_col0\" class=\"data row11 col0\" >Fold Number</td>\n",
       "      <td id=\"T_f7a2b_row11_col1\" class=\"data row11 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_f7a2b_row12_col0\" class=\"data row12 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_f7a2b_row12_col1\" class=\"data row12 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_f7a2b_row13_col0\" class=\"data row13 col0\" >Use GPU</td>\n",
       "      <td id=\"T_f7a2b_row13_col1\" class=\"data row13 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_f7a2b_row14_col0\" class=\"data row14 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_f7a2b_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_f7a2b_row15_col0\" class=\"data row15 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_f7a2b_row15_col1\" class=\"data row15 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_f7a2b_row16_col0\" class=\"data row16 col0\" >USI</td>\n",
       "      <td id=\"T_f7a2b_row16_col1\" class=\"data row16 col1\" >08f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_f7a2b_row17_col0\" class=\"data row17 col0\" >Transform Target</td>\n",
       "      <td id=\"T_f7a2b_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7a2b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_f7a2b_row18_col0\" class=\"data row18 col0\" >Transform Target Method</td>\n",
       "      <td id=\"T_f7a2b_row18_col1\" class=\"data row18 col1\" >box-cox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe81d585310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe11029f2574b039dd2ced1dbb3bfea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Processing: ', max=4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>12:05:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 5 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>CatBoost Regressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  \n",
       "                                                                  \n",
       "Initiated  . . . . . . . . . . . . . . . . . .            12:05:30\n",
       "Status     . . . . . . . . . . . . . . . . . .     Fitting 5 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  CatBoost Regressor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MAE, MSE, RMSE, R2, RMSLE, MAPE]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m setup(data\u001b[38;5;241m=\u001b[39mtrain_data, target\u001b[38;5;241m=\u001b[39mlipid_name, test_data\u001b[38;5;241m=\u001b[39mtest_data, \n\u001b[1;32m     18\u001b[0m       fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, use_gpu\u001b[38;5;241m=\u001b[39muse_gpu, session_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, preprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fold_shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatboost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Retrieve cross-validation results\u001b[39;00m\n\u001b[1;32m     24\u001b[0m metrics \u001b[38;5;241m=\u001b[39m pull()\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/pycaret/regression.py:887\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(estimator, fold, round, cross_validation, fit_kwargs, groups, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(\n\u001b[1;32m    781\u001b[0m     estimator: Union[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    782\u001b[0m     fold: Optional[Union[\u001b[38;5;28mint\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    789\u001b[0m ):\n\u001b[1;32m    791\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;124;03m    This function trains and evaluates the performance of a given estimator \u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;124;03m    using cross validation. The output of this function is a score grid with \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;124;03m      \u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mtabular\u001b[38;5;241m.\u001b[39mcreate_model_supervised(\n\u001b[1;32m    888\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    889\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[1;32m    891\u001b[0m         cross_validation\u001b[38;5;241m=\u001b[39mcross_validation,\n\u001b[1;32m    892\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[1;32m    893\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    894\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    895\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    896\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/pycaret/internal/tabular.py:3090\u001b[0m, in \u001b[0;36mcreate_model_supervised\u001b[0;34m(estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, verbose, system, X_train_data, y_train_data, metrics, display, **kwargs)\u001b[0m\n\u001b[1;32m   3087\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross validating with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_jobs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_jobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3089\u001b[0m model_fit_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 3090\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m   3091\u001b[0m     pipeline_with_model,\n\u001b[1;32m   3092\u001b[0m     data_X,\n\u001b[1;32m   3093\u001b[0m     data_y,\n\u001b[1;32m   3094\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m   3095\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m   3096\u001b[0m     scoring\u001b[38;5;241m=\u001b[39mmetrics_dict,\n\u001b[1;32m   3097\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[1;32m   3098\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m   3099\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3100\u001b[0m     error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   3101\u001b[0m )\n\u001b[1;32m   3102\u001b[0m model_fit_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3103\u001b[0m model_fit_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model_fit_end \u001b[38;5;241m-\u001b[39m model_fit_start)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Select 20 random lipids from the columns\n",
    "selected_lipids = random.sample(list(y_train.columns), 20)\n",
    "\n",
    "# Initialize DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Lipid', 'R2_mean', 'MAPE_mean'])\n",
    "\n",
    "for lipid_name in tqdm(selected_lipids, desc='Processing Lipids'):\n",
    "    # Concatenate the lipid column with the training and testing features\n",
    "    train_data = pd.concat([X_train, y_train[lipid_name]], axis=1)\n",
    "    test_data = pd.concat([X_test, y_test[lipid_name]], axis=1)\n",
    "    \n",
    "    # Setup PyCaret for each lipid\n",
    "    setup(data=train_data, target=lipid_name, test_data=test_data, \n",
    "          fold=5, use_gpu=use_gpu, session_id=42, preprocess=False, fold_shuffle=True)\n",
    "\n",
    "    # Create the model\n",
    "    model = create_model('catboost')\n",
    "    \n",
    "    # Retrieve cross-validation results\n",
    "    metrics = pull()\n",
    "    \n",
    "    r2_mean = metrics.loc['Mean','R2']\n",
    "    mape_mean = metrics.loc['Mean', 'MAPE']\n",
    "    \n",
    "    # Append the results to the DataFrame\n",
    "    results_df = results_df.append({'Lipid': lipid_name, 'R2_mean': r2_mean, 'MAPE_mean': mape_mean}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lipid</th>\n",
       "      <th>R2_mean</th>\n",
       "      <th>MAPE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC(32:1)</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>0.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cer 40:2</td>\n",
       "      <td>0.6186</td>\n",
       "      <td>0.4171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HexCer 38:1</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.4486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PG(36:1)</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PA(40:5)</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PS(O-34:0(OH))</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.4230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PC 33:0</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.3663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HexCer 42:2</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>0.6315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PE(O-34:1)</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LPC O-16:2</td>\n",
       "      <td>0.6454</td>\n",
       "      <td>0.2056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HexCer 42:1</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>0.3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PE(30:1)</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.7497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cer 42:2</td>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.4437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PC(30:0)</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PA 40:6</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.6982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PE 40:4</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>0.4389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PG(36:1(OH))</td>\n",
       "      <td>0.5394</td>\n",
       "      <td>0.3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LPC 18:0</td>\n",
       "      <td>0.4041</td>\n",
       "      <td>0.1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PC 32:0</td>\n",
       "      <td>0.8103</td>\n",
       "      <td>0.1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PE O-39:7</td>\n",
       "      <td>0.3134</td>\n",
       "      <td>0.2093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Lipid  R2_mean  MAPE_mean\n",
       "0         PC(32:1)    0.7191     0.2333\n",
       "1          Cer 40:2   0.6186     0.4171\n",
       "2       HexCer 38:1   0.7410     0.4486\n",
       "3         PG(36:1)    0.6684     0.1797\n",
       "4         PA(40:5)    0.7475     0.2083\n",
       "5   PS(O-34:0(OH))    0.7480     0.4230\n",
       "6           PC 33:0   0.5663     0.3663\n",
       "7       HexCer 42:2   0.7995     0.6315\n",
       "8       PE(O-34:1)    0.5247     0.1999\n",
       "9        LPC O-16:2   0.6454     0.2056\n",
       "10      HexCer 42:1   0.7240     0.3773\n",
       "11        PE(30:1)    0.2112     0.7497\n",
       "12         Cer 42:2   0.5877     0.4437\n",
       "13        PC(30:0)    0.4629     0.1961\n",
       "14          PA 40:6   0.3109     0.6982\n",
       "15          PE 40:4   0.3730     0.4389\n",
       "16    PG(36:1(OH))    0.5394     0.3577\n",
       "17         LPC 18:0   0.4041     0.1896\n",
       "18          PC 32:0   0.8103     0.1897\n",
       "19        PE O-39:7   0.3134     0.2093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the results\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_49628\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_49628_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_49628_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_49628_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_49628_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_49628_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_49628_row1_col1\" class=\"data row1 col1\" >LPC O- 18:3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_49628_row2_col0\" class=\"data row2 col0\" >Original Data</td>\n",
       "      <td id=\"T_49628_row2_col1\" class=\"data row2 col1\" >(62576, 501)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_49628_row3_col0\" class=\"data row3 col0\" >Missing Values</td>\n",
       "      <td id=\"T_49628_row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_49628_row4_col0\" class=\"data row4 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_49628_row4_col1\" class=\"data row4 col1\" >500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_49628_row5_col0\" class=\"data row5 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_49628_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_49628_row6_col0\" class=\"data row6 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_49628_row6_col1\" class=\"data row6 col1\" >(62576, 500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_49628_row7_col0\" class=\"data row7 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_49628_row7_col1\" class=\"data row7 col1\" >(26819, 500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_49628_row8_col0\" class=\"data row8 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_49628_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_49628_row9_col0\" class=\"data row9 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_49628_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_49628_row10_col0\" class=\"data row10 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_49628_row10_col1\" class=\"data row10 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_49628_row11_col0\" class=\"data row11 col0\" >Fold Number</td>\n",
       "      <td id=\"T_49628_row11_col1\" class=\"data row11 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_49628_row12_col0\" class=\"data row12 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_49628_row12_col1\" class=\"data row12 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_49628_row13_col0\" class=\"data row13 col0\" >Use GPU</td>\n",
       "      <td id=\"T_49628_row13_col1\" class=\"data row13 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_49628_row14_col0\" class=\"data row14 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_49628_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_49628_row15_col0\" class=\"data row15 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_49628_row15_col1\" class=\"data row15 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_49628_row16_col0\" class=\"data row16 col0\" >USI</td>\n",
       "      <td id=\"T_49628_row16_col1\" class=\"data row16 col1\" >b991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_49628_row17_col0\" class=\"data row17 col0\" >Transform Target</td>\n",
       "      <td id=\"T_49628_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_49628_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_49628_row18_col0\" class=\"data row18 col0\" >Transform Target Method</td>\n",
       "      <td id=\"T_49628_row18_col1\" class=\"data row18 col1\" >box-cox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe848f7e210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f68ebd6ed742eca71ef850ad3c0508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Processing: ', max=4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>12:10:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 5 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>CatBoost Regressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  \n",
       "                                                                  \n",
       "Initiated  . . . . . . . . . . . . . . . . . .            12:10:51\n",
       "Status     . . . . . . . . . . . . . . . . . .     Fitting 5 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  CatBoost Regressor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MAE, MSE, RMSE, R2, RMSLE, MAPE]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "TBB Warning: The number of workers is currently limited to 1. The request for 15 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m s \u001b[38;5;241m=\u001b[39m setup(data\u001b[38;5;241m=\u001b[39mtrain_data, target\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mcolumns[i], test_data\u001b[38;5;241m=\u001b[39mtest_data, \n\u001b[1;32m     13\u001b[0m           fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, session_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, use_gpu\u001b[38;5;241m=\u001b[39muse_gpu, preprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fold_shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create and train the model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatboost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Retrieving cross-validation results\u001b[39;00m\n\u001b[1;32m     19\u001b[0m metrics \u001b[38;5;241m=\u001b[39m pull()\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/pycaret/regression.py:887\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(estimator, fold, round, cross_validation, fit_kwargs, groups, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(\n\u001b[1;32m    781\u001b[0m     estimator: Union[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    782\u001b[0m     fold: Optional[Union[\u001b[38;5;28mint\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    789\u001b[0m ):\n\u001b[1;32m    791\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;124;03m    This function trains and evaluates the performance of a given estimator \u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;124;03m    using cross validation. The output of this function is a score grid with \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;124;03m      \u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mtabular\u001b[38;5;241m.\u001b[39mcreate_model_supervised(\n\u001b[1;32m    888\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    889\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[1;32m    891\u001b[0m         cross_validation\u001b[38;5;241m=\u001b[39mcross_validation,\n\u001b[1;32m    892\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[1;32m    893\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    894\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    895\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    896\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/pycaret/internal/tabular.py:3090\u001b[0m, in \u001b[0;36mcreate_model_supervised\u001b[0;34m(estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, verbose, system, X_train_data, y_train_data, metrics, display, **kwargs)\u001b[0m\n\u001b[1;32m   3087\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross validating with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_jobs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_jobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3089\u001b[0m model_fit_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 3090\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m   3091\u001b[0m     pipeline_with_model,\n\u001b[1;32m   3092\u001b[0m     data_X,\n\u001b[1;32m   3093\u001b[0m     data_y,\n\u001b[1;32m   3094\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m   3095\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m   3096\u001b[0m     scoring\u001b[38;5;241m=\u001b[39mmetrics_dict,\n\u001b[1;32m   3097\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[1;32m   3098\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m   3099\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3100\u001b[0m     error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   3101\u001b[0m )\n\u001b[1;32m   3102\u001b[0m model_fit_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3103\u001b[0m model_fit_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model_fit_end \u001b[38;5;241m-\u001b[39m model_fit_start)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/.conda/envs/ml-project-2-genelipids/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=['Lipid', 'R2_mean', 'MAPE_mean', 'Top_Features'])\n",
    "\n",
    "for i in tqdm(range(len(y_train.columns)), desc='Processing Lipids'):\n",
    "    # Extract the column name for the current index\n",
    "    lipid_name = y_train.columns[i]\n",
    "\n",
    "    # Concatenate the lipid column with the training and testing features\n",
    "    train_data = pd.concat([X_train, y_train.iloc[:, i]], axis=1)\n",
    "    test_data = pd.concat([X_test, y_test.iloc[:, i]], axis=1)\n",
    "    \n",
    "    # Setup PyCaret for each lipid\n",
    "    s = setup(data=train_data, target=y_train.columns[i], test_data=test_data, \n",
    "              fold=5, session_id=42, use_gpu=use_gpu, preprocess=False, fold_shuffle=True)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_model('catboost')\n",
    "    \n",
    "    # Retrieving cross-validation results\n",
    "    metrics = pull()\n",
    "    \n",
    "    r2_mean = metrics.loc['Mean', 'R2']\n",
    "    mape_mean = metrics.loc['Mean', 'MAPE']\n",
    "    \n",
    "    # Accessing feature importances directly from the model\n",
    "    feature_importance_df = pd.DataFrame({'Feature': model.feature_names_, 'Importance': model.feature_importances_})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).head(5)\n",
    "    top_features = feature_importance_df.to_dict(orient='records')\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    results_df = results_df.append({'Lipid': lipid_name, 'R2_mean': r2_mean, 'MAPE_mean': mape_mean, 'Top_Features': top_features}, ignore_index=True)\n",
    "    \n",
    "    display(results_df)\n",
    "    \n",
    "results_df.to_csv('results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
